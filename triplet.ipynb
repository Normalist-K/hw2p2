{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel auto reload modules when the underlying code is chaneged, instead of having to reset the runtime.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as ttf\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "\n",
    "from models.convnext import convnext_t, my_convnext\n",
    "from datasets.triplet import TripletDataset\n",
    "from datasets.classification import ClassificationTestSet\n",
    "from datasets.verification import VerificationDataset\n",
    "from datasets.transform import AlbumTransforms, train_transforms, val_transforms\n",
    "from utils.utils import weight_decay_custom, compute_kl_loss, SAM\n",
    "from run import train, test, inference, face_embedding, verification_inference, gen_cls_submission, gen_ver_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/shared/youngkim/hw2p2'\n",
    "CLS_DIR = os.path.join(BASE_DIR, '11-785-s22-hw2p2-classification')\n",
    "VER_DIR = os.path.join(BASE_DIR, '11-785-s22-hw2p2-verification')\n",
    "\n",
    "CLS_TRAIN_DIR = os.path.join(CLS_DIR, \"classification/classification/train\") # This is a smaller subset of the data. Should change this to classification/classification/train\n",
    "CLS_VAL_DIR = os.path.join(CLS_DIR, \"classification/classification/dev\")\n",
    "CLS_TEST_DIR = os.path.join(CLS_DIR, \"classification/classification/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TripletDataset(CLS_TRAIN_DIR, transform=AlbumTransforms(train_transforms))\n",
    "val_dataset = TripletDataset(CLS_VAL_DIR, transform=AlbumTransforms(val_transforms))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256,\n",
    "                        shuffle=True, drop_last=True, num_workers=2)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=256, shuffle=False,\n",
    "                        drop_last=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3c4dd319ecd10802be1c77dfdfd6b25af6a7d32bbb2d7a1dac30da2e89c7158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('happywhale')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
