{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/class/cmu/DL/cmu-hw2p2\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import train, test, inference, face_embedding, verification_inference, gen_cls_submission, gen_ver_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as ttf\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "\n",
    "from models.cnn import BaselineCNN, VGG16\n",
    "from datasets.classification import ClassificationTestSet\n",
    "from datasets.verification import VerificationDataset\n",
    "from datasets.transform import AlbumTransforms, train_transforms, val_transforms\n",
    "from utils.utils import weight_decay_custom, compute_kl_loss, SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/shared/youngkim/hw2p2'\n",
    "CLS_DIR = os.path.join(BASE_DIR, '11-785-s22-hw2p2-classification')\n",
    "VER_DIR = os.path.join(BASE_DIR, '11-785-s22-hw2p2-verification')\n",
    "\n",
    "CLS_TRAIN_DIR = os.path.join(CLS_DIR, \"train_subset/train_subset\") # This is a smaller subset of the data. Should change this to classification/classification/train\n",
    "CLS_VAL_DIR = os.path.join(CLS_DIR, \"classification/classification/dev\")\n",
    "CLS_TEST_DIR = os.path.join(CLS_DIR, \"classification/classification/test\")\n",
    "\n",
    "VER_VAL_DIR = os.path.join(VER_DIR, 'verification/verification/dev')\n",
    "VER_TEST_DIR = os.path.join(VER_DIR, 'verification/verification/test')\n",
    "\n",
    "val_veri_dataset = VerificationDataset(VER_VAL_DIR,\n",
    "                                        AlbumTransforms(val_transforms))\n",
    "test_veri_dataset = VerificationDataset(VER_TEST_DIR,\n",
    "                                        AlbumTransforms(val_transforms))\n",
    "\n",
    "val_ver_loader = torch.utils.data.DataLoader(val_veri_dataset, batch_size=128, \n",
    "                                                shuffle=False, num_workers=1)\n",
    "test_ver_loader = torch.utils.data.DataLoader(test_veri_dataset, batch_size=128, \n",
    "                                                shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VGG16().to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: /shared/youngkim/hw2p2/weights/vgg16.pth\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('/shared/youngkim/hw2p2/weights/vgg16.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Model loaded: {'/shared/youngkim/hw2p2/weights/vgg16.pth'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model\n",
    "\n",
    "val_feats_dict = face_embedding(best_model, val_ver_loader, device)\n",
    "    \n",
    "val_veri_csv = os.path.join(VER_DIR, \"verification/verification/verification_dev.csv\")\n",
    "similarity_metric = nn.CosineSimilarity(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000b28b024.jpg'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(val_feats_dict.items())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(val_feats_dict.items())[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_A</th>\n",
       "      <th>image_B</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev/ab001b21a1.jpg</td>\n",
       "      <td>dev/10246770ce.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev/c692b5fa6b.jpg</td>\n",
       "      <td>dev/299becf799.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev/d0dc5318e4.jpg</td>\n",
       "      <td>dev/3aac902136.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev/f9643ca7b5.jpg</td>\n",
       "      <td>dev/6f300f3205.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev/95ccb4131a.jpg</td>\n",
       "      <td>dev/3d207ca2b2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_A             image_B  match\n",
       "0  dev/ab001b21a1.jpg  dev/10246770ce.jpg      1\n",
       "1  dev/c692b5fa6b.jpg  dev/299becf799.jpg      0\n",
       "2  dev/d0dc5318e4.jpg  dev/3aac902136.jpg      0\n",
       "3  dev/f9643ca7b5.jpg  dev/6f300f3205.jpg      1\n",
       "4  dev/95ccb4131a.jpg  dev/3d207ca2b2.jpg      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(val_veri_csv).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Veri: 100%|██████████| 166800/166800 [00:12<00:00, 12946.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8937404067355124\n"
     ]
    }
   ],
   "source": [
    "# Now, loop through the csv and compare each pair, getting the similarity between them\n",
    "similarity_metric = nn.CosineSimilarity(dim=0)\n",
    "similarity_metric.to(device)\n",
    "\n",
    "pred_similarities = []\n",
    "gt_similarities = []\n",
    "for line in tqdm(open(val_veri_csv).read().splitlines()[1:], position=0, leave=True, desc='Veri'): # skip header\n",
    "    img_path1, img_path2, gt = line.split(\",\")\n",
    "\n",
    "    # TODO: Use the similarity metric\n",
    "    # How to use these img_paths? What to do with the features?\n",
    "    \n",
    "    feat1 = val_feats_dict[img_path1.split(\"/\")[-1]]\n",
    "    feat2 = val_feats_dict[img_path2.split(\"/\")[-1]]\n",
    "    \n",
    "    similarity = similarity_metric(feat1, feat2)\n",
    "\n",
    "    pred_similarities.append(similarity.cpu())\n",
    "    gt_similarities.append(int(gt))\n",
    "\n",
    "pred_similarities = np.array(pred_similarities)\n",
    "gt_similarities = np.array(gt_similarities)\n",
    "\n",
    "auc = roc_auc_score(gt_similarities, pred_similarities)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# auc = verification(val_veri_csv, val_feats_dict, similarity_metric, device)\n",
    "# print(\"Verification AUC: \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding: 100%|██████████| 188/188 [00:45<00:00,  4.10it/s]\n",
      "Veri_infer: 100%|██████████| 667600/667600 [00:52<00:00, 12762.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ver_submission saved.\n"
     ]
    }
   ],
   "source": [
    "test_feats_dict = face_embedding(best_model, test_ver_loader, device)\n",
    "\n",
    "test_veri_csv = os.path.join(VER_DIR, \"verification/verification/verification_test.csv\")\n",
    "pred_similarities = verification_inference(test_veri_csv, test_feats_dict, similarity_metric, device)\n",
    "\n",
    "# gen_ver_submission\n",
    "sub_path = '/shared/youngkim/hw2p2/submissions'\n",
    "save_name = 'vgg16'\n",
    "assert len(pred_similarities) == 667600\n",
    "test_names = [i for i in range(len(pred_similarities))]\n",
    "submission = pd.DataFrame(zip(test_names, pred_similarities), columns=['id', 'match'])\n",
    "submission.to_csv(os.path.join(sub_path, f'{save_name}_ver_sub.csv'), index=False)\n",
    "\n",
    "print(\"ver_submission saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3c4dd319ecd10802be1c77dfdfd6b25af6a7d32bbb2d7a1dac30da2e89c7158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('happywhale')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
